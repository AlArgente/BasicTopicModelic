{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import models\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from topic_modeling_20newsgroups import preprocessing, tokenize, do_stem, lemmatize\n",
    "# Used later in the document\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "# import pickle to save and load the dictionary and the corpus\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling Fetch_20newsgroups\n",
    "\n",
    "Jupyter Notebook for topic modeling the Fetch_20newsgroups from sklearn.\n",
    "In this script I will be using LDA as topic modeling algorithm.\n",
    "I will use spacy and gensim, but I won't use NLTK for preprocessing\n",
    "the text. \n",
    "\n",
    "I usually use nltk for all the text preprocessing, but I willuse\n",
    "other libraries such as spacy and gensim to learn new ways of\n",
    "preprocessing the text. For lemmatizing I will use spacy, but if\n",
    "stemming is selected, I will use nltk. I've found that nltk stemmer\n",
    "and lemmatizer are better thatn spacy's one, because nltk has\n",
    "better algorithms/rules for that. Also it could be a nice option to use\n",
    "stanza, a NLP package made by Stanford University."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of targets for the fetch_20newsgroup: 20\n",
      "The targets are: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n",
      "\n",
      "Example of news in this problem:\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "# To see the complete information about the dataset, uncommnet the next line.\n",
    "# print(train.DESCR)\n",
    "\n",
    "# There are twenty classes in this dataset.\n",
    "print('Number of targets for the fetch_20newsgroup:', len(newsgroups_train.target_names))\n",
    "print('The targets are:', newsgroups_train.target_names)\n",
    "print('\\n\\nExample of news in this problem:')\n",
    "print(newsgroups_train.data[0])\n",
    "\n",
    "# Take news data and target\n",
    "train_text, y_train = newsgroups_train.datta, newsgroups_train.target\n",
    "test_text, y_test = newsgroups_test.data, newsgroups_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = preprocessing(train_text)\n",
    "test_text = preprocessing(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the vocabulary and the corpus for training the ldamodel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = gensim.corpora.Dictionary(train_text)\n",
    "corpus = [id2word.doc2bow(text) for text in train_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the topic modeling model**\n",
    "\n",
    "Here we have to use the corpus and the dictionary we've prepared. In the *num_topics* we use 20, because this dataset has 20 different classes. *chunksize* refes to the number of documents used in each training chunk. *passes* refers to the total number of training passes. \n",
    "\n",
    "*alpha* is set to auto, as well as *eta* (which is by default as auto), the value will be 1.0/num_topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=20,\n",
    "        random_state=42,\n",
    "        update_every=1,\n",
    "        chunksize=100,\n",
    "        passes=10,\n",
    "        alpha='auto',\n",
    "        per_word_topics=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is fitted, we can show the 20 topics, and the most important words in it. Here we use the function *print_topics*, that by default shows the 10 most important words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.823*\"*\" + 0.006*\"!\" + 0.004*\"circuit\" + 0.004*\"baseball\" + 0.002*\"captain\" + 0.002*\"consequence\" + 0.002*\"    \" + 0.002*\"consult\" + 0.002*\"funny\" + 0.002*\"Ted\"'),\n",
       " (1,\n",
       "  '0.084*\"\\n    \" + 0.082*\"\\n \" + 0.071*\",\" + 0.053*\"x\" + 0.049*\";\" + 0.048*\"%\" + 0.037*\"\"\" + 0.035*\"/\" + 0.033*\"]\" + 0.031*\"[\"'),\n",
       " (2,\n",
       "  '0.243*\"\\n   \" + 0.170*\"\\n  \" + 0.063*\"\\n\\n   \" + 0.048*\"\\n\\n  \" + 0.035*\"}\" + 0.014*\"\\n          \" + 0.014*\"telnet\" + 0.009*\"{\" + 0.009*\"message\" + 0.006*\"implementation\"'),\n",
       " (3,\n",
       "  '0.839*\"=\" + 0.019*\"-\" + 0.011*\"|\" + 0.006*\"@\" + 0.004*\"Baker\" + 0.002*\",\" + 0.002*\"||\" + 0.002*\"w\" + 0.001*\"amazing\" + 0.001*\"!\"'),\n",
       " (4,\n",
       "  '0.394*\"#\" + 0.015*\"ATI\" + 0.014*\"DoD\" + 0.007*\"pixel\" + 0.006*\"ex\" + 0.004*\"ultra\" + 0.004*\"BC\" + 0.002*\"adjust\" + 0.002*\"{\" + 0.002*\"231\"'),\n",
       " (5,\n",
       "  '0.127*\".\" + 0.123*\"\\n\" + 0.117*\",\" + 0.059*\" \" + 0.023*\"\"\" + 0.019*\"\\n\\n\" + 0.009*\"?\" + 0.007*\")\" + 0.007*\"(\" + 0.006*\"think\"'),\n",
       " (6,\n",
       "  '0.013*\"simm\" + 0.004*\"Plymouth\" + 0.003*\"simms\" + 0.001*\"octopus\" + 0.000*\"60ns\" + 0.000*\"VRAM\" + 0.000*\"vram\" + 0.000*\"950\" + 0.000*\"Q800\" + 0.000*\"slot\"'),\n",
       " (7,\n",
       "  '0.047*\"space\" + 0.046*\"Space\" + 0.035*\"NASA\" + 0.029*\"launch\" + 0.027*\"tv\" + 0.025*\"orbit\" + 0.023*\"vs.\" + 0.018*\"satellite\" + 0.017*\"mission\" + 0.012*\"shuttle\"'),\n",
       " (8,\n",
       "  '0.416*\">\" + 0.245*\"\\n\" + 0.063*\"<\" + 0.060*\"|\" + 0.024*\"\\'\" + 0.020*\",\" + 0.020*\"write\" + 0.018*\"article\" + 0.016*\":\" + 0.012*\"(\"'),\n",
       " (9,\n",
       "  '0.719*\"_\" + 0.031*\"|\" + 0.018*\"/\" + 0.015*\"\\\\\" + 0.013*\"              \" + 0.008*\"                    \" + 0.005*\"  \" + 0.003*\"/|\" + 0.002*\"\\\\/\" + 0.002*\"AL\"'),\n",
       " (10,\n",
       "  '0.060*\" \" + 0.041*\"\\t\" + 0.041*\")\" + 0.038*\"  \" + 0.036*\"(\" + 0.034*\"-\" + 0.030*\"\\n\" + 0.028*\",\" + 0.020*\"   \" + 0.019*\".\"'),\n",
       " (11,\n",
       "  '0.000*\"enamoured\" + 0.000*\"f117a\" + 0.000*\"Porject\" + 0.000*\"Sebrenitsa\" + 0.000*\"Stealh\" + 0.000*\"alastair@farli.otago.ac.nz\" + 0.000*\"athomson@otago.ac.nz\" + 0.000*\"dunedin\" + 0.000*\"Mig\" + 0.000*\"euphanism\"'),\n",
       " (12,\n",
       "  '0.313*\"+\" + 0.065*\"M\" + 0.037*\"`\" + 0.029*\"m\" + 0.013*\"VAX\" + 0.011*\"VMS\" + 0.010*\"/\" + 0.010*\"C\" + 0.008*\"voltage\" + 0.007*\"VNEWS\"'),\n",
       " (13,\n",
       "  '0.000*\"enamoured\" + 0.000*\"f117a\" + 0.000*\"Porject\" + 0.000*\"Sebrenitsa\" + 0.000*\"Stealh\" + 0.000*\"alastair@farli.otago.ac.nz\" + 0.000*\"athomson@otago.ac.nz\" + 0.000*\"dunedin\" + 0.000*\"Mig\" + 0.000*\"euphanism\"'),\n",
       " (14,\n",
       "  '0.155*\"\\n\" + 0.154*\":\" + 0.056*\"\\n\\n\" + 0.053*\"-\" + 0.047*\"(\" + 0.046*\")\" + 0.027*\".\" + 0.025*\",\" + 0.025*\"?\" + 0.020*\"line\"'),\n",
       " (15,\n",
       "  '0.066*\"\"\" + 0.040*\",\" + 0.027*\".\" + 0.023*\"God\" + 0.022*\"\\n\\n\" + 0.015*\"\\n\" + 0.014*\"evidence\" + 0.012*\"people\" + 0.010*\"?\" + 0.010*\"reason\"'),\n",
       " (16,\n",
       "  '0.020*\"408\" + 0.019*\"guest\" + 0.017*\"241\" + 0.015*\"9760\" + 0.012*\"Communication\" + 0.007*\"NETCOM\" + 0.004*\"SF\" + 0.004*\"Toshiba\" + 0.000*\"3401\" + 0.000*\"os/2\"'),\n",
       " (17,\n",
       "  '0.000*\"enamoured\" + 0.000*\"f117a\" + 0.000*\"Porject\" + 0.000*\"Sebrenitsa\" + 0.000*\"Stealh\" + 0.000*\"alastair@farli.otago.ac.nz\" + 0.000*\"athomson@otago.ac.nz\" + 0.000*\"dunedin\" + 0.000*\"Mig\" + 0.000*\"euphanism\"'),\n",
       " (18,\n",
       "  '0.044*\"Israel\" + 0.026*\"israeli\" + 0.019*\"soldier\" + 0.017*\"village\" + 0.016*\"physical\" + 0.014*\"turkish\" + 0.014*\"war\" + 0.014*\"kill\" + 0.012*\"Jews\" + 0.012*\"attack\"'),\n",
       " (19,\n",
       "  '0.159*\"key\" + 0.082*\"chip\" + 0.028*\"algorithm\" + 0.026*\"Clipper\" + 0.022*\"DES\" + 0.022*\"RSA\" + 0.015*\"crypto\" + 0.011*\"Chip\" + 0.009*\"announcement\" + 0.009*\"enforcement\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have shown each topic and the 10 most important words. In this way we can know a little about each topic, and what are they about by the targets we have. \n",
    "\n",
    "The topic 10 does not tells anthing about the topic, text may need more cleaning before being processed, and this happen as well in the topics 8 and 9. Nevertheless the topic 18 goes about politics, or the topic 19 that goes about science, in concrete about electronics and crypt. In the other hand, the topic 0 is about sports.\n",
    "\n",
    "As the model seems to be not detecting some topics well, we may want to get the coherence of the topics detected, so we know if we need to go some steps before or we can continue. To do so, we will use the CoherenceModel from gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.460689981510683\n"
     ]
    }
   ],
   "source": [
    "coherence = models.CoherenceModel(model=lda_model, texts=train_text, dictionary=id2word, \n",
    "                                  coherence='u_mass', corpus=corpus)\n",
    "\n",
    "# We can use 'c_v' and 'u_mass' among other. 'c_v' goes between 0 and 1, and 'u_mass' goes between -14, 14.\n",
    "\n",
    "print(coherence.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 'u_mass' goes between -14,14, we should get a better coherence than -4.46, at least more close to 0. This happens because we should have clean the text more, deleting '(', '\\n', so we could get better topics.\n",
    "\n",
    "To clean the text, we could use some aditional functions using the re package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:14: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:16: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:12: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:14: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:16: DeprecationWarning: invalid escape sequence \\w\n",
      "<ipython-input-38-d49e513ee608>:12: DeprecationWarning: invalid escape sequence \\S\n",
      "  text = [re.sub('\\S*@\\S*\\s', '', news) for news in text]\n",
      "<ipython-input-38-d49e513ee608>:14: DeprecationWarning: invalid escape sequence \\s\n",
      "  text = [re.sub('\\s+', ' ', news) for news in text]\n",
      "<ipython-input-38-d49e513ee608>:16: DeprecationWarning: invalid escape sequence \\w\n",
      "  text = [re.sub('[^\\w\\s]', '', news) for news in text]\n"
     ]
    }
   ],
   "source": [
    "# This functions shold be used before tokenizing the text\n",
    "def cleaning_functions(text):\n",
    "    \"\"\"Function to clean the text. This function delete\n",
    "    emails, new line character, etc.\n",
    "    Args:\n",
    "        text(list): text to clean.\n",
    "    Returns:\n",
    "        list: text cleaned.\n",
    "    \"\"\"\n",
    "    # Removing emails. We could use a better regular expression\n",
    "    # but for this case this is enough.\n",
    "    text = [re.sub('\\S*@\\S*\\s', '', news) for news in text]\n",
    "    # Removing new line character\n",
    "    text = [re.sub('\\s+', ' ', news) for news in text]\n",
    "    # Removing punctuation\n",
    "    text = [re.sub('[^\\w\\s]', '', news) for news in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will clean the data and retrain the lda_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = newsgroups_train.data\n",
    "train_text = cleaning_functions(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = preprocessing(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = gensim.corpora.Dictionary(train_text)\n",
    "corpus = [id2word.doc2bow(text) for text in train_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=20,\n",
    "        random_state=42,\n",
    "        update_every=1,\n",
    "        chunksize=100,\n",
    "        passes=10,\n",
    "        alpha='auto',\n",
    "        per_word_topics=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4833556254374036\n"
     ]
    }
   ],
   "source": [
    "coherence = models.CoherenceModel(model=lda_model, texts=train_text, dictionary=id2word, \n",
    "                                  coherence='c_v', corpus=corpus)\n",
    "\n",
    "# We can use 'c_v' and 'u_mass' among other. 'c_v' goes between 0 and 1, and 'u_mass' goes between -14, 14.\n",
    "\n",
    "print(coherence.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can get the perplexity of the model. This will show us how good the model is. The lower the value, the better the model is. This measure can be calculated with the lda_model we've trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -15.56366731906751\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print the topics now, we will see a better defined topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.052*\"patient\" + 0.032*\"server\" + 0.026*\"Public\" + 0.024*\"Access\" + 0.023*\"insurance\" + 0.021*\"Unix\" + 0.019*\"Online\" + 0.016*\"procedure\" + 0.015*\"guest\" + 0.015*\"electronic\"'),\n",
       " (1,\n",
       "  '0.025*\"gun\" + 0.017*\"kill\" + 0.015*\"soldier\" + 0.015*\"war\" + 0.014*\"village\" + 0.014*\"weapon\" + 0.012*\"crime\" + 0.012*\"attack\" + 0.012*\"turkish\" + 0.012*\"government\"'),\n",
       " (2,\n",
       "  '0.097*\"game\" + 0.093*\"team\" + 0.053*\"win\" + 0.049*\"play\" + 0.032*\"year\" + 0.029*\"fan\" + 0.025*\"score\" + 0.018*\"run\" + 0.015*\"division\" + 0.012*\"hit\"'),\n",
       " (3,\n",
       "  '0.012*\"Mozumder\" + 0.010*\"SN\" + 0.000*\"atheism\" + 0.000*\"atheist\" + 0.000*\"freewill\" + 0.000*\"Angels\" + 0.000*\"b64635studentcwruedu\" + 0.000*\"Aario\" + 0.000*\"marriage\" + 0.000*\"Eros\"'),\n",
       " (4,\n",
       "  '0.100*\"drive\" + 0.059*\"Mac\" + 0.038*\"IDE\" + 0.036*\"controller\" + 0.031*\"SCSI\" + 0.024*\"Brian\" + 0.022*\"bus\" + 0.014*\"BIOS\" + 0.013*\"deserve\" + 0.012*\"Green\"'),\n",
       " (5,\n",
       "  '0.032*\"ram\" + 0.021*\"buffer\" + 0.021*\"MB\" + 0.017*\"Finland\" + 0.008*\"0400\" + 0.007*\"Helsinki\" + 0.005*\"Philips\" + 0.005*\"DRAM\" + 0.005*\"static\" + 0.004*\"refresh\"'),\n",
       " (6,\n",
       "  '0.008*\"neat\" + 0.002*\"Chhabra\" + 0.002*\"Deepak\" + 0.002*\"Goalie\" + 0.002*\"bee\" + 0.002*\"Solar\" + 0.002*\"Terresterial\" + 0.002*\"stplistsca\" + 0.002*\"ISTS\" + 0.001*\"Devices\"'),\n",
       " (7,\n",
       "  '0.033*\"x\" + 0.019*\"use\" + 0.018*\"file\" + 0.018*\"program\" + 0.014*\"X\" + 0.012*\"include\" + 0.011*\"available\" + 0.010*\"message\" + 0.010*\"window\" + 0.010*\"information\"'),\n",
       " (8,\n",
       "  '0.106*\"1\" + 0.072*\"2\" + 0.045*\"3\" + 0.043*\"4\" + 0.029*\"5\" + 0.028*\"25\" + 0.025*\"6\" + 0.024*\"7\" + 0.015*\"8\" + 0.015*\"10\"'),\n",
       " (9,\n",
       "  '0.835*\"_\" + 0.003*\"Louis\" + 0.003*\"     \" + 0.003*\"NewsSoftware\" + 0.003*\"VAXVMS\" + 0.003*\"Cubs\" + 0.002*\"wiring\" + 0.002*\"VNEWS\" + 0.002*\"radius\" + 0.001*\"PL6\"'),\n",
       " (10,\n",
       "  '0.019*\"Electronics\" + 0.013*\"bag\" + 0.012*\"partner\" + 0.008*\"mathew\" + 0.008*\"correction\" + 0.007*\"period\" + 0.006*\"der\" + 0.005*\"substantially\" + 0.005*\"satisfactory\" + 0.004*\"Mantis\"'),\n",
       " (11,\n",
       "  '0.028*\"Don\" + 0.010*\"ruin\" + 0.005*\"MOA\" + 0.003*\"sufficiently\" + 0.001*\"Ehrlich\" + 0.000*\"cursor\" + 0.000*\"Diamond\" + 0.000*\"Lindbergh\" + 0.000*\"Cherry\" + 0.000*\"player\"'),\n",
       " (12,\n",
       "  '0.040*\"Organization\" + 0.037*\"Subject\" + 0.032*\"Lines\" + 0.021*\"University\" + 0.012*\"like\" + 0.011*\"nntppostinghost\" + 0.010*\"nt\" + 0.010*\"line\" + 0.010*\"m\" + 0.009*\"thank\"'),\n",
       " (13,\n",
       "  '0.104*\"Israel\" + 0.068*\"israeli\" + 0.039*\"Jews\" + 0.033*\"jewish\" + 0.024*\"terrorist\" + 0.022*\"arab\" + 0.021*\"Law\" + 0.020*\"Islam\" + 0.017*\"Iran\" + 0.014*\"islamic\"'),\n",
       " (14,\n",
       "  '0.318*\" \" + 0.059*\"  \" + 0.037*\"write\" + 0.028*\"article\" + 0.020*\"0\" + 0.012*\"   \" + 0.006*\"Organization\" + 0.006*\"line\" + 0.006*\"    \" + 0.005*\"Subject\"'),\n",
       " (15,\n",
       "  '0.039*\"key\" + 0.027*\"chip\" + 0.019*\"government\" + 0.019*\"public\" + 0.016*\"physical\" + 0.016*\"law\" + 0.013*\"system\" + 0.012*\"encryption\" + 0.012*\"discussion\" + 0.011*\"use\"'),\n",
       " (16,\n",
       "  '0.031*\"block\" + 0.031*\"package\" + 0.023*\"device\" + 0.020*\"library\" + 0.019*\"waste\" + 0.019*\"society\" + 0.018*\"cop\" + 0.015*\"trap\" + 0.015*\"tool\" + 0.013*\"ensure\"'),\n",
       " (17,\n",
       "  '0.011*\"subsequent\" + 0.009*\"Navy\" + 0.004*\"Militia\" + 0.004*\"WASHINGTON\" + 0.002*\"Military\" + 0.002*\"Corps\" + 0.002*\"donate\" + 0.000*\"tape\" + 0.000*\"gonorrhea\" + 0.000*\"CDC\"'),\n",
       " (18,\n",
       "  '0.044*\"Space\" + 0.037*\"space\" + 0.029*\"launch\" + 0.024*\"NASA\" + 0.022*\"orbit\" + 0.020*\"moon\" + 0.019*\"Earth\" + 0.018*\"satellite\" + 0.017*\"mission\" + 0.013*\"fuel\"'),\n",
       " (19,\n",
       "  '0.031*\"nt\" + 0.014*\"people\" + 0.014*\"think\" + 0.011*\"know\" + 0.010*\"say\" + 0.009*\"like\" + 0.009*\"time\" + 0.008*\"God\" + 0.008*\"thing\" + 0.008*\"come\"')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the text we have a better coherence, and better topics detected, so this will be the model we will analyze. As we got a good model, we could save it for future uses. We can use the save function to save the model as a pickle object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save('lda_fetch20news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the model, we only have to use the load function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = models.ldamodel.LdaModel.load('lda_fetch20news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the model, and understand more the topics we've extracted, we will use the pyLDAvis package, which is compatible with the LDA model from gensim. It prints interative chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/.local/lib/python3.8/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/usr/lib/python3/dist-packages/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "/usr/lib/python3/dist-packages/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "/usr/lib/python3/dist-packages/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "/usr/lib/python3/dist-packages/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n"
     ]
    }
   ],
   "source": [
    "# Use enable_notebook to use the package\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus=corpus, dictionary=id2word)\n",
    "# vis # uncomment to show the interative chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could end the analysis here, just using pyLDAvis to understad how the topics have been formed, but we're going further. \n",
    "\n",
    "We know we had to look for 20 targets, but what if we don't know about the topics we're searching?? We have to search for the number of topics that adapt better to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_by_model(dictionary, corpus, text, start=2, limit=20, step=1):\n",
    "    \"\"\"Function that computes the c_v coherence for multiple LDA models while changing\n",
    "    the number of topics.\n",
    "    Args:\n",
    "        dictionary: Gensim dictionary\n",
    "        corpus: Gensim corpus\n",
    "        text (list): text preprocessed\n",
    "        start (int, optional): first number of topics to test\n",
    "        limit (int, optional): max number of topics to test\n",
    "        step (int, optional): number of steps while increasing the topics\n",
    "    Returns:\n",
    "        lda_model_list: list with the lda models\n",
    "        coherence_values_list: list with the coherence values for the models\n",
    "    \"\"\"\n",
    "    lda_model_list = []\n",
    "    coherence_values_list = []\n",
    "    for i in range(start, limit, step):\n",
    "        lda_model = models.ldamodel.LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=i,\n",
    "            per_word_topics=True,\n",
    "            alpha='auto',\n",
    "            passes=10,\n",
    "            chunksize=100\n",
    "        )\n",
    "        lda_model_list.append(lda_model)\n",
    "        cv = models.CoherenceModel(lda_model, texts=text, corpus=corpus, \n",
    "                                   dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values_list.append(cv.get_coherence())\n",
    "        \n",
    "    return lda_model_list, coherence_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_by_model(dictionary=id2word, corpus=corpus, text=train_text,\n",
    "                                                         step=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the evolution of the coherence score as we increse the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=20; start=2; step=5;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 20 targets, but as we can see in the target names, there are 7 main topics, and there are some subtopics for each main topic. That is why we get a similar coherence score with 7 and with 20 topics with the LDA.\n",
    "\n",
    "We can also use KMeans, from scikit-learn to try to detect also the clusters and then use LDA to study the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
